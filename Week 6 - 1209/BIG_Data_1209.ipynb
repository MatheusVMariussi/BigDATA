{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gm_l5cJFkLm",
        "outputId": "e4e10395-5f2b-4914-d08c-c4f26cd8597e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mrjob in /usr/local/lib/python3.12/dist-packages (0.7.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from mrjob) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install mrjob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file avg_temp_month_combiner.py\n",
        "#temp média por mes usando combiner\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class ForestFireAvgTempCombiner(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    fields = value.split(',')\n",
        "    if len(fields) == 13:\n",
        "      try:\n",
        "        month = fields[2]\n",
        "        temp = float(fields[8])\n",
        "        yield month, [temp, 1]\n",
        "      except ValueError:\n",
        "        pass\n",
        "\n",
        "  def combiner(self, key, value):\n",
        "    partial_sum = 0\n",
        "    partial_count = 0\n",
        "    for v in value:\n",
        "      partial_sum += v[0]\n",
        "      partial_count += v[1]\n",
        "    #ao invez de calcular a media, o combiner retorna somente as somas\n",
        "    yield key, (partial_sum, partial_count)\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum_values = 0\n",
        "    count = 0\n",
        "    for v in value:\n",
        "      sum_values += v[0]\n",
        "      count += v[1]\n",
        "    avg_temp = sum_values/count\n",
        "    yield key, avg_temp\n",
        "\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper,\n",
        "                   combiner=self.combiner,\n",
        "                   reducer=self.reducer)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  ForestFireAvgTempCombiner.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdWC-RewFsIv",
        "outputId": "d5e4543c-69d8-4c8a-db4e-546264e859dd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avg_temp_month_combiner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!python avg_temp_month_combiner.py forestfireinput.csv --output-dir=output\n",
        "!cat /content/output/part-* > /content/output/avg_temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuAMuGWrF3-a",
        "outputId": "27f1f5ba-27ec-4cee-aa0e-5ab6d207c565"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/avg_temp_month_combiner.root.20250912.143507.870774\n",
            "job output is in output\n",
            "Removing temp directory /tmp/avg_temp_month_combiner.root.20250912.143507.870774...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordCount using COMBINER"
      ],
      "metadata": {
        "id": "pAaaP5oQLHgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file wordcount_combined.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.job import MRStep\n",
        "import re\n",
        "\n",
        "class WordCountCombined(MRJob):\n",
        "\n",
        "  def mapper(self, _, value):\n",
        "    words = re.findall(\"[a-z]+\", value.lower())\n",
        "    for word in words:\n",
        "      yield word, 1\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    yield key, sum(value)\n",
        "\n",
        "# o combiner é exatamente o mesmo codigo do reducer, logo:\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper,\n",
        "                   combiner=self.reducer,\n",
        "                   reducer=self.reducer)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordCountCombined.run()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYB_bHc6LGhE",
        "outputId": "690f08e7-993d-4e4c-f546-6182f0361ede"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting wordcount_combined.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output2\n",
        "!python wordcount_combined.py frankenstein.txt --output-dir=output2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln8imfRzLQ15",
        "outputId": "cb023049-d27e-4c05-8fd2-6ce528a43ed8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/wordcount_combined.root.20250912.143508.694967\n",
            "job output is in output2\n",
            "Removing temp directory /tmp/wordcount_combined.root.20250912.143508.694967...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make it sorted"
      ],
      "metadata": {
        "id": "gUOXRdvDTXhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file avg_temp_month_sorted.py\n",
        "#temp média por mes usando combiner\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class ForestFireAvgTempSorted(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    fields = value.split(',')\n",
        "    if len(fields) == 13:\n",
        "      try:\n",
        "        month = fields[2]\n",
        "        temp = float(fields[8])\n",
        "        yield month, [temp, 1]\n",
        "      except ValueError:\n",
        "        pass\n",
        "\n",
        "  def combiner(self, key, value):\n",
        "    partial_sum = 0\n",
        "    partial_count = 0\n",
        "    for v in value:\n",
        "      partial_sum += v[0]\n",
        "      partial_count += v[1]\n",
        "    #ao invez de calcular a media, o combiner retorna somente as somas\n",
        "    yield key, (partial_sum, partial_count)\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum_values = 0\n",
        "    count = 0\n",
        "    for v in value:\n",
        "      sum_values += v[0]\n",
        "      count += v[1]\n",
        "    avg_temp = sum_values/count\n",
        "    yield \"Avarage\", [key, avg_temp]\n",
        "\n",
        "  def reducer_sort(self, _, value):\n",
        "    # transforma o value de interador para lista\n",
        "    # invertendo (mes, temp) para (temp, mes)\n",
        "    # para permitir a ordenacao por temperatura\n",
        "    pairs = []\n",
        "    for month, avg_temp in value:\n",
        "      pairs.append((avg_temp, month))\n",
        "    #ordenacao pela temperatura\n",
        "    pairs.sort()\n",
        "    # gera a saida no formato (chave, valor)\n",
        "    # que deve ser (mes, temperatura)\n",
        "    for avg_temp, month in pairs:\n",
        "      yield month, avg_temp\n",
        "\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper,\n",
        "                   combiner=self.combiner,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_sort)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  ForestFireAvgTempSorted.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "153Jb0MBQzCz",
        "outputId": "84b0f9a1-7b1b-4907-b270-8fe278e86a2c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avg_temp_month_sorted.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output3/\n",
        "!python avg_temp_month_sorted.py forestfireinput.csv --output-dir=output3\n",
        "!cat /content/output3/part-* > /content/output3/avg_temp_sorted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnntL8mzRLSM",
        "outputId": "62f45e96-a68f-4612-9afb-31c2bf461a99"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 2...\n",
            "Creating temp directory /tmp/avg_temp_month_sorted.root.20250912.143510.023076\n",
            "Running step 2 of 2...\n",
            "job output is in output3\n",
            "Removing temp directory /tmp/avg_temp_month_sorted.root.20250912.143510.023076...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the highest avg temp"
      ],
      "metadata": {
        "id": "xlj4qYZsTaQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file highest_avg_temp_month.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class ForestFireAvgTempHighest(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    fields = value.split(',')\n",
        "    if len(fields) == 13:\n",
        "      try:\n",
        "        month = fields[2]\n",
        "        temp = float(fields[8])\n",
        "        yield month, [temp, 1]\n",
        "      except ValueError:\n",
        "        pass\n",
        "\n",
        "  def combiner(self, key, value):\n",
        "    partial_sum = 0\n",
        "    partial_count = 0\n",
        "    for v in value:\n",
        "      partial_sum += v[0]\n",
        "      partial_count += v[1]\n",
        "    #ao invez de calcular a media, o combiner retorna somente as somas\n",
        "    yield key, (partial_sum, partial_count)\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum_values = 0\n",
        "    count = 0\n",
        "    for v in value:\n",
        "      sum_values += v[0]\n",
        "      count += v[1]\n",
        "    avg_temp = sum_values/count\n",
        "    yield \"Avarage\", [key, avg_temp]\n",
        "\n",
        "  def reducer_max(self, _, value):\n",
        "    max_value = -1\n",
        "    for v in value:\n",
        "      if v[1] > max_value:\n",
        "        max_value = v[1]\n",
        "        month = v[0]\n",
        "    yield \"Highest\", [month, max_value]\n",
        "\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper,\n",
        "                   combiner=self.combiner,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_max)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  ForestFireAvgTempHighest.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0cA0ZPqTePi",
        "outputId": "12b9d9f5-aee0-4b25-cee2-76c130a99a1d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting highest_avg_temp_month.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output4/\n",
        "!python highest_avg_temp_month.py forestfireinput.csv --output-dir=output4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tmYUn7pVjCH",
        "outputId": "ac583f01-8026-45a0-987c-c76557c8943b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 2...\n",
            "Creating temp directory /tmp/highest_avg_temp_month.root.20250912.143619.362196\n",
            "Running step 2 of 2...\n",
            "job output is in output4\n",
            "Removing temp directory /tmp/highest_avg_temp_month.root.20250912.143619.362196...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diferenca entre media de cada mes e a media anual"
      ],
      "metadata": {
        "id": "-QS2M3P-XNd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file temp_diffs.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class ForestFireTempDiffs(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    fields = value.split(',')\n",
        "    if len(fields) == 13:\n",
        "      try:\n",
        "        month = fields[2]\n",
        "        temp = float(fields[8])\n",
        "        yield month, [temp, 1]\n",
        "        yield \"Yearly\", [temp, 1]\n",
        "      except ValueError:\n",
        "        pass\n",
        "\n",
        "  def combiner(self, key, value):\n",
        "    partial_sum = 0\n",
        "    partial_count = 0\n",
        "    for v in value:\n",
        "      partial_sum += v[0]\n",
        "      partial_count += v[1]\n",
        "    #ao invez de calcular a media, o combiner retorna somente as somas\n",
        "    yield key, (partial_sum, partial_count)\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum_values = 0\n",
        "    count = 0\n",
        "    for v in value:\n",
        "      sum_values += v[0]\n",
        "      count += v[1]\n",
        "    avg_temp = sum_values/count\n",
        "    yield \"Avarage\", [key, avg_temp]\n",
        "\n",
        "  def reducer_diff(self, _, value):\n",
        "    yearly_temp = 0\n",
        "    month_temp = []\n",
        "    for v0, v1 in value:\n",
        "      if v0 == \"Yearly\":\n",
        "        yearly_temp = v1\n",
        "      else:\n",
        "        month_temp.append((v0, v1))\n",
        "\n",
        "    for v0, v1 in month_temp:\n",
        "      diff = v1 - yearly_temp\n",
        "      yield v0, diff\n",
        "\n",
        "\n",
        "  def steps(self):\n",
        "    return [MRStep(mapper=self.mapper,\n",
        "                   combiner=self.combiner,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_diff)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  ForestFireTempDiffs.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3iuWLfhXCx_",
        "outputId": "5bdbc2e4-6969-4aa8-c45f-e25ab808c984"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting temp_diffs.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output5/\n",
        "!python temp_diffs.py forestfireinput.csv --output-dir=output5\n",
        "!cat /content/output5/part-* > /content/output5/temp_diffs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_cqN_9BXInn",
        "outputId": "05fbf75d-e4c2-4c15-ad09-99aa9ec3ad8f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 2...\n",
            "Creating temp directory /tmp/temp_diffs.root.20250912.150123.182672\n",
            "Running step 2 of 2...\n",
            "job output is in output5\n",
            "Removing temp directory /tmp/temp_diffs.root.20250912.150123.182672...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FASTA ENTROPY"
      ],
      "metadata": {
        "id": "Q4SS3yNud6kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file entropy_fasta.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import math\n",
        "\n",
        "class EntropyFasta(MRJob):\n",
        "\n",
        "  def mapper(self, _, value):\n",
        "    line = list(value) #split por caracter\n",
        "    if line[0] == \">\":\n",
        "      pass\n",
        "    else:\n",
        "      for c in line:\n",
        "        yield c, 1\n",
        "        yield \"total\", 1\n",
        "\n",
        "  def reducerA(self, key, value):\n",
        "    yield \"entropy\", [key, sum(value)]\n",
        "\n",
        "  def reducerB(self, key, value):\n",
        "    # encontra o valor de \"total\" para calcular a probabilidade de cada char\n",
        "    total = 0\n",
        "    char_freq = []\n",
        "\n",
        "    for k,v in value:\n",
        "      if k == \"total\":\n",
        "        total = v\n",
        "      else:\n",
        "        char_freq.append((k, v))\n",
        "\n",
        "    # calcula a entropia\n",
        "    for k,v in char_freq:\n",
        "      prob = v/total\n",
        "      entropy = -prob*math.log(prob, 2)\n",
        "      yield k, entropy\n",
        "\n",
        "  def steps(self):\n",
        "    return [\n",
        "      MRStep(mapper=self.mapper, reducer=self.reducerA),\n",
        "      MRStep(reducer=self.reducerB)\n",
        "    ]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  EntropyFasta.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQVduxRTd69j",
        "outputId": "e1f851d7-78c9-4d20-fcaf-e444262f7c22"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing entropy_fasta.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output6/\n",
        "!python entropy_fasta.py Sars_cov_2.fasta --output-dir=output6\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltiVkbqti5TV",
        "outputId": "4a7d9caf-131b-4e04-f561-bce8436f87f8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 2...\n",
            "Creating temp directory /tmp/entropy_fasta.root.20250912.153209.125825\n",
            "Running step 2 of 2...\n",
            "job output is in output6\n",
            "Removing temp directory /tmp/entropy_fasta.root.20250912.153209.125825...\n"
          ]
        }
      ]
    }
  ]
}