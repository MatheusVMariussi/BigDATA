{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVhI7IiW9qjL",
        "outputId": "45b88479-ce7c-40ae-f2eb-6e1ab4f37f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mrjob in /usr/local/lib/python3.12/dist-packages (0.7.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from mrjob) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install mrjob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file wordcount_unstructured.py\n",
        "\n",
        "import re\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class WordCount(MRJob):\n",
        "\n",
        "  # tanto o mapper quanto o reducer, recebem (chave, valor) como entrada\n",
        "  def mapper(self, _, value):\n",
        "    words = re.findall(\"[a-z]+\", value.lower())\n",
        "    for word in words:\n",
        "      yield word, 1\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum = 0\n",
        "    for v in value:\n",
        "      sum+=1\n",
        "    yield key, sum\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordCount.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFljE8Fd-7UF",
        "outputId": "1958f1d0-e12a-4aa7-b802-8ca92577c34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting wordcount_unstructured.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!python wordcount_unstructured.py frankenstein.txt --output-dir=output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygHn8Aa-DG_Y",
        "outputId": "69c1c2e4-32e0-409d-8094-32968ae21774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/wordcount_unstructured.root.20250829.135455.534902\n",
            "job output is in output\n",
            "Removing temp directory /tmp/wordcount_unstructured.root.20250829.135455.534902...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file wordlen_unstructured.py\n",
        "\n",
        "import re\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class WordLen(MRJob):\n",
        "\n",
        "  # tanto o mapper quanto o reducer, recebem (chave, valor) como entrada\n",
        "  def mapper(self, _, value):\n",
        "    words = re.findall(\"[a-z]+\", value.lower())\n",
        "    for word in words:\n",
        "      yield len(word), 1\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    sum = 0\n",
        "    for v in value:\n",
        "      sum+=1\n",
        "    yield key, sum\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordLen.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFKojrFLDdIo",
        "outputId": "c79082db-1472-4450-f9a9-43c1f0aca8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting wordlen_unstructured.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output2\n",
        "!python wordlen_unstructured.py frankenstein.txt --output-dir=output2\n",
        "\n",
        "!cat output2/part-* > output2/wordlen_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK4Vbf5iIG1i",
        "outputId": "20d094d6-560a-4f06-9533-6b7ef8098551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/wordlen_unstructured.root.20250829.140516.146597\n",
            "job output is in output2\n",
            "Removing temp directory /tmp/wordlen_unstructured.root.20250829.140516.146597...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dados semi-estruturados**"
      ],
      "metadata": {
        "id": "lIq13q4FLVrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d reviews_Amazon_Instant_Video_5.json.gz"
      ],
      "metadata": {
        "id": "WoRbgVb_IIY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 reviews_Amazon_Instant_Video_5.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWT5gYYJLhQY",
        "outputId": "b5d4bb06-08a7-4dcf-8310-3772b1be3e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"reviewerID\": \"A11N155CW1UV02\", \"asin\": \"B000H00VBQ\", \"reviewerName\": \"AdrianaM\", \"helpful\": [0, 0], \"reviewText\": \"I had big expectations because I love English TV, in particular Investigative and detective stuff but this guy is really boring. It didn't appeal to me at all.\", \"overall\": 2.0, \"summary\": \"A little bit boring for me\", \"unixReviewTime\": 1399075200, \"reviewTime\": \"05 3, 2014\"}\n",
            "{\"reviewerID\": \"A3BC8O2KCL29V2\", \"asin\": \"B000H00VBQ\", \"reviewerName\": \"Carol T\", \"helpful\": [0, 0], \"reviewText\": \"I highly recommend this series. It is a must for anyone who is yearning to watch \\\"grown up\\\" television. Complex characters and plots to keep one totally involved. Thank you Amazin Prime.\", \"overall\": 5.0, \"summary\": \"Excellent Grown Up TV\", \"unixReviewTime\": 1346630400, \"reviewTime\": \"09 3, 2012\"}\n",
            "{\"reviewerID\": \"A60D5HQFOTSOM\", \"asin\": \"B000H00VBQ\", \"reviewerName\": \"Daniel Cooper \\\"dancoopermedia\\\"\", \"helpful\": [0, 1], \"reviewText\": \"This one is a real snoozer. Don't believe anything you read or hear, it's awful. I had no idea what the title means. Neither will you.\", \"overall\": 1.0, \"summary\": \"Way too boring for me\", \"unixReviewTime\": 1381881600, \"reviewTime\": \"10 16, 2013\"}\n",
            "{\"reviewerID\": \"A1RJPIGRSNX4PW\", \"asin\": \"B000H00VBQ\", \"reviewerName\": \"J. Kaplan \\\"JJ\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Mysteries are interesting.  The tension between Robson and the tall blond is good but not always believable.  She often seemed uncomfortable.\", \"overall\": 4.0, \"summary\": \"Robson Green is mesmerizing\", \"unixReviewTime\": 1383091200, \"reviewTime\": \"10 30, 2013\"}\n",
            "{\"reviewerID\": \"A16XRPF40679KG\", \"asin\": \"B000H00VBQ\", \"reviewerName\": \"Michael Dobey\", \"helpful\": [1, 1], \"reviewText\": \"This show always is excellent, as far as british crime or mystery showsgoes this is one of the best ever made.  The stories are well done and the acting is top notch with interesting twists in the realistic and brutal storylines.  This show pulls no punches as it enters into the twisted minds of criminals and the profiler psychiatrist who helps out in a northern english city police force. The show looks like it is shot in Manchester but it is called by another name in the show.  One episode is not on this disc the excellent 'prayer of the bone\\\" which is on a seperate disc.  Still crime shows don't get much better than this one on either side of the ocean.  It's just a great show that never has had a less than well made episode. Unfortunately like all British shows you only get about five shows a year ,  but these are an hour and a half shows , still one could hope for at least 8 of these a year.  The realism and depth of the main character Tony Hill as protrayed by the excellent Robson Green is well worth viewing because he just makes this role truly part of himself in everyway.  I bet he went to crime scenes even in real life to research his role.  But the writers too must be applauded for their way above average stories.  Lets hope this show continues on for many years to come.\", \"overall\": 5.0, \"summary\": \"Robson green and great writing\", \"unixReviewTime\": 1234310400, \"reviewTime\": \"02 11, 2009\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file wordcount_semistructured.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "import json\n",
        "\n",
        "class WordCountAmazon(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    line = json.loads(value)\n",
        "    review_text = line['reviewText']\n",
        "    words = re.findall(\"[a-z]+\", review_text.lower())\n",
        "    for word in words:\n",
        "      yield word, 1\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    yield key, sum(value)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  WordCountAmazon.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm87fd4TLk6E",
        "outputId": "0fc71262-1381-433f-d8df-0468c8ad2fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting wordcount_semistructured.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output_amazon\n",
        "!python wordcount_semistructured.py reviews_Amazon_Instant_Video_5.json --output-dir=output_amazon\n",
        "\n",
        "!cat output_amazon/part-* > output_amazon/amazon_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMU1vyfwLtpo",
        "outputId": "2821114e-4658-4601-d8ea-c092524ab4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/wordcount_semistructured.root.20250829.142342.028215\n",
            "job output is in output_amazon\n",
            "Removing temp directory /tmp/wordcount_semistructured.root.20250829.142342.028215...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file overall_semistructured.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "import json\n",
        "\n",
        "class OverAllAmazon(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    line = json.loads(value)\n",
        "    overall = float(line['overall'])\n",
        "    if overall <= 2.5:\n",
        "      yield \"overall_less_2.5\", 1\n",
        "    else:\n",
        "      yield \"overall_greater_2.5\", 1\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    yield key, sum(value)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  OverAllAmazon.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbdsFmSkOoCB",
        "outputId": "b7521d3a-9be3-4b8d-bfd8-dff3c2ba93f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting overall_semistructured.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output_amazonOverall\n",
        "!python overall_semistructured.py reviews_Amazon_Instant_Video_5.json --output-dir=output_amazonOverall\n",
        "\n",
        "!cat output_amazonOverall/part-* > output_amazonOverall/amazon_finalOverall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESUincUhP__W",
        "outputId": "f1d32c7a-68da-46a3-f7b2-f13ea730c1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/overall_semistructured.root.20250829.143752.164609\n",
            "job output is in output_amazonOverall\n",
            "Removing temp directory /tmp/overall_semistructured.root.20250829.143752.164609...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 california_housing.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg1Cat-KTvSu",
        "outputId": "8537c6f4-7f97-4613-c508-2d1c195f5f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n",
            "-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000\n",
            "-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000\n",
            "-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000\n",
            "-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file maxpopulation_structured.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class maxpopulation_structured(MRJob):\n",
        "  def mapper(self, _, value):\n",
        "    fields = value.split(',')\n",
        "    # verifica se tem todas as colunas\n",
        "    if len(fields) == 9:\n",
        "      try:\n",
        "        population = float(fields[5])\n",
        "        yield \"population\", population\n",
        "      except ValueError:\n",
        "        pass #ignora se nao for float\n",
        "\n",
        "\n",
        "  def reducer(self, key, value):\n",
        "    yield \"max_population\", max(value)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  maxpopulation_structured.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2zv2iSfTeHd",
        "outputId": "bbb6b52e-bb44-4668-f1d7-90a4bc1e52a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting maxpopulation_structured.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output_California\n",
        "!python maxpopulation_structured.py california_housing.csv --output-dir=output_California\n",
        "\n",
        "!cat output_California/part-* > output_California/amazon_finalPopulation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_wT5zjiTlqI",
        "outputId": "97a19e17-b7a5-46f9-cadc-9a20294b66a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/maxpopulation_structured.root.20250829.150247.223803\n",
            "job output is in output_California\n",
            "Removing temp directory /tmp/maxpopulation_structured.root.20250829.150247.223803...\n"
          ]
        }
      ]
    }
  ]
}